{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzLTCfR+o5aYLz6CCGvxGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EastHuni/lg-aimers/blob/main/LTSF___OPTUNA_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLqKjODK-KK1",
        "outputId": "06246b24-c420-464d-89b4-be6ec4ce50c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.42)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLuOPZJe9s8U",
        "outputId": "791dd52f-af9f-4c79-dc75-8f32d2a2621e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4251228950.py:66: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
            "  df['공휴일'] = df['영업일자'].isin(kr_holidays).astype(int)\n",
            "[I 2025-08-06 20:02:26,231] A new study created in memory with name: no-name-f97ec754-e835-44ae-9d85-1f571820f361\n",
            "/tmp/ipython-input-4251228950.py:145: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  x_val = torch.tensor([last_seq]).float().to(DEVICE)\n",
            "[I 2025-08-06 20:07:45,116] Trial 0 finished with value: 187.4406952964939 and parameters: {'lr': 0.00010635797480554176, 'batch_size': 8, 'epochs': 25, 'dropout': 0.02005748735990437}. Best is trial 0 with value: 187.4406952964939.\n",
            "[I 2025-08-06 20:16:01,001] Trial 1 finished with value: 186.93834128613673 and parameters: {'lr': 0.00013570329095388285, 'batch_size': 8, 'epochs': 41, 'dropout': 0.018344113350375835}. Best is trial 1 with value: 186.93834128613673.\n",
            "[I 2025-08-06 20:18:06,334] Trial 2 finished with value: 186.06835970333015 and parameters: {'lr': 0.0006806458018098577, 'batch_size': 16, 'epochs': 20, 'dropout': 0.3870664802526545}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:28:12,264] Trial 3 finished with value: 186.53403174194045 and parameters: {'lr': 0.0002311933052567727, 'batch_size': 8, 'epochs': 50, 'dropout': 0.1054110559347804}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:33:41,095] Trial 4 finished with value: 187.0383833074956 and parameters: {'lr': 0.0013936540457746434, 'batch_size': 8, 'epochs': 27, 'dropout': 0.2674906230734313}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:35:41,898] Trial 5 finished with value: 186.94238867395364 and parameters: {'lr': 0.00013836850318205046, 'batch_size': 8, 'epochs': 10, 'dropout': 0.07183390915507454}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:40:20,015] Trial 6 finished with value: 186.4427532958701 and parameters: {'lr': 0.0007590171744893785, 'batch_size': 16, 'epochs': 45, 'dropout': 0.41511680530497747}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:42:10,207] Trial 7 finished with value: 187.11885708794247 and parameters: {'lr': 0.006944208811619266, 'batch_size': 32, 'epochs': 33, 'dropout': 0.060175711282130784}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:43:57,090] Trial 8 finished with value: 186.1009048923986 and parameters: {'lr': 0.00961663363359261, 'batch_size': 32, 'epochs': 32, 'dropout': 0.3714711236719575}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:46:00,059] Trial 9 finished with value: 186.092449317462 and parameters: {'lr': 0.0004115022206793425, 'batch_size': 32, 'epochs': 37, 'dropout': 0.444635330373242}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:47:46,841] Trial 10 finished with value: 186.67338450619567 and parameters: {'lr': 0.003079390168565368, 'batch_size': 16, 'epochs': 17, 'dropout': 0.2553433893454718}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:49:51,265] Trial 11 finished with value: 186.76381351312773 and parameters: {'lr': 0.0004897021502235937, 'batch_size': 16, 'epochs': 20, 'dropout': 0.4958207385615537}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:51:50,838] Trial 12 finished with value: 186.97350129971244 and parameters: {'lr': 0.00038872151534648903, 'batch_size': 32, 'epochs': 36, 'dropout': 0.36948602155835913}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:53:54,399] Trial 13 finished with value: 186.27403445310478 and parameters: {'lr': 0.0016184236099745304, 'batch_size': 16, 'epochs': 20, 'dropout': 0.48920711826218566}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:56:04,178] Trial 14 finished with value: 186.85100321152132 and parameters: {'lr': 0.00039779641587361144, 'batch_size': 32, 'epochs': 39, 'dropout': 0.3171192872169883}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:57:13,177] Trial 15 finished with value: 187.58204650213074 and parameters: {'lr': 0.0008220643498956748, 'batch_size': 16, 'epochs': 11, 'dropout': 0.42937352428467285}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 20:58:43,502] Trial 16 finished with value: 186.44513919479888 and parameters: {'lr': 0.0030654955211761687, 'batch_size': 32, 'epochs': 27, 'dropout': 0.1723146723889608}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 21:00:24,544] Trial 17 finished with value: 187.37728123021796 and parameters: {'lr': 0.0006332461860124534, 'batch_size': 16, 'epochs': 16, 'dropout': 0.3238895413508075}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 21:01:43,642] Trial 18 finished with value: 188.43679945489765 and parameters: {'lr': 0.00022040159516647563, 'batch_size': 32, 'epochs': 24, 'dropout': 0.4349433948732474}. Best is trial 2 with value: 186.06835970333015.\n",
            "[I 2025-08-06 21:06:15,369] Trial 19 finished with value: 186.6470126354376 and parameters: {'lr': 0.0013331521110124193, 'batch_size': 16, 'epochs': 44, 'dropout': 0.19076970991149692}. Best is trial 2 with value: 186.06835970333015.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Best SMAPE: 186.06835970333015\n",
            "✅ Best Params: {'lr': 0.0006806458018098577, 'batch_size': 16, 'epochs': 20, 'dropout': 0.3870664802526545}\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os, glob, random, re, zipfile, json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import holidays\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import optuna\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/LG/open.zip'\n",
        "extract_path = '/content/LG_data'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "train = pd.read_csv('/content/LG_data/train/train.csv')\n",
        "kr_holidays = holidays.KR(years=range(2023, 2026))\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "class NLinear(nn.Module):\n",
        "    def __init__(self, input_len=28, output_len=7, input_dim=5, dropout=0.0):\n",
        "        super(NLinear, self).__init__()\n",
        "        self.linear = nn.Linear(input_len, output_len)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (B, C, T)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)      # (B, C, output_len)\n",
        "        return x.permute(0, 2, 1)[:, :, 0]  # (B, output_len)\n",
        "\n",
        "LOOKBACK, PREDICT = 28, 7 # 이건 고정\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def make_features(df):\n",
        "    df = df.sort_values(['영업장명_메뉴명', '영업일자']).copy()\n",
        "    df['영업일자'] = pd.to_datetime(df['영업일자'])\n",
        "    df['요일'] = df['영업일자'].dt.dayofweek\n",
        "    df['공휴일'] = df['영업일자'].isin(kr_holidays).astype(int)\n",
        "    df['lag_1'] = df.groupby('영업장명_메뉴명')['매출수량'].shift(1)\n",
        "    df['rolling_7_mean'] = (\n",
        "        df.groupby('영업장명_메뉴명')['매출수량']\n",
        "        .shift(1).rolling(7, min_periods=1).mean().reset_index(0, drop=True))\n",
        "\n",
        "    feature_cols = ['lag_1', 'rolling_7_mean']\n",
        "    df[feature_cols] = df.groupby('영업장명_메뉴명')[feature_cols].ffill()\n",
        "    rolling_avg = (\n",
        "        df.groupby('영업장명_메뉴명')['매출수량']\n",
        "        .transform(lambda x: x.shift(1).rolling(7, min_periods=1).mean()))\n",
        "\n",
        "    for col in feature_cols:\n",
        "        df[col] = df[col].fillna(rolling_avg)\n",
        "    df[feature_cols] = df[feature_cols].fillna(0)\n",
        "\n",
        "    return df[['영업일자', '영업장명_메뉴명', '매출수량', '요일', '공휴일'] + feature_cols]\n",
        "\n",
        "train = make_features(train)\n",
        "\n",
        "\n",
        "def smape(y_true, y_pred):\n",
        "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
        "    diff = np.abs(y_true - y_pred) / denominator\n",
        "    diff[denominator == 0] = 0.0\n",
        "    return np.mean(diff) * 100\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])\n",
        "    epochs = trial.suggest_int('epochs', 10, 50)\n",
        "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
        "\n",
        "    total_preds, total_trues = [], []\n",
        "\n",
        "    for store_menu, group in train.groupby('영업장명_메뉴명'):\n",
        "        store_train = group.sort_values('영업일자').copy()\n",
        "        if len(store_train) < LOOKBACK + PREDICT + 7:\n",
        "            continue\n",
        "\n",
        "        features = ['매출수량', '요일', '공휴일', 'lag_1', 'rolling_7_mean']\n",
        "        scaler = MinMaxScaler()\n",
        "        store_train[features] = scaler.fit_transform(store_train[features])\n",
        "        values = store_train[features].values\n",
        "\n",
        "        val_target = values[-7:, 0]\n",
        "        train_values = values[:-7]\n",
        "\n",
        "        X_train, y_train = [], []\n",
        "        for i in range(len(train_values) - LOOKBACK - PREDICT + 1):\n",
        "            X_train.append(train_values[i:i+LOOKBACK])\n",
        "            y_train.append(train_values[i+LOOKBACK:i+LOOKBACK+PREDICT, 0])\n",
        "\n",
        "        if len(X_train) == 0:\n",
        "            continue\n",
        "\n",
        "        X_train = torch.tensor(np.array(X_train)).float().to(DEVICE)\n",
        "        y_train = torch.tensor(np.array(y_train)).float().to(DEVICE)\n",
        "\n",
        "        model = NLinear(input_len=LOOKBACK, output_len=PREDICT, input_dim=5, dropout=dropout).to(DEVICE)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "        criterion = torch.nn.MSELoss()\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(epochs):\n",
        "            idx = torch.randperm(len(X_train))\n",
        "            for i in range(0, len(X_train), batch_size):\n",
        "                batch_idx = idx[i:i+batch_size]\n",
        "                x_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "                output = model(x_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        last_seq = train_values[-LOOKBACK:]\n",
        "        x_val = torch.tensor([last_seq]).float().to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(x_val).squeeze().cpu().numpy()\n",
        "\n",
        "        restored = []\n",
        "        for i in range(PREDICT):\n",
        "            dummy = np.zeros((1, 5))\n",
        "            dummy[0, 0] = pred_scaled[i]\n",
        "            restored_val = scaler.inverse_transform(dummy)[0, 0]\n",
        "            restored.append(restored_val)\n",
        "\n",
        "        total_preds.extend(restored)\n",
        "        total_trues.extend(val_target)\n",
        "\n",
        "    return smape(np.array(total_trues), np.array(total_preds))\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "with open(\"best_params.json\", \"w\") as f:\n",
        "    json.dump(study.best_trial.params, f)\n",
        "\n",
        "print(\"\\n✅ Best SMAPE:\", study.best_value)\n",
        "print(\"✅ Best Params:\", study.best_trial.params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "buxShNDB96xC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}